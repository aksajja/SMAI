{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model -- Undercomplete AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as weight_init\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#parameters\n",
    "batch_size = 128\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "\n",
    "#Loading the train set file\n",
    "dataset = datasets.MNIST(root='./data',\n",
    "                            transform=preprocess,  \n",
    "                            download=True)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes=[4, 8,12]\n",
    "input_size = 28*28\n",
    "#hidden_size = 256\n",
    "# out_sizes=[16,32,64,128]\n",
    "num_classes = 2\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "momentum_rate = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, int(hidden_size/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden_size/2), num_classes),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_classes, int(hidden_size/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden_size/2), hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h = self.encoder(x)\n",
    "        xr = self.decoder(h)\n",
    "        return xr,h\n",
    "\n",
    "#Misc functions\n",
    "def loss_plot(losses):\n",
    "    max_epochs = len(losses)\n",
    "    times = list(range(1, max_epochs+1))\n",
    "    plt.figure(figsize=(30, 7))\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"cross-entropy loss\")\n",
    "    return plt.plot(times, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA  False\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Using CUDA ', use_cuda)\n",
    "\n",
    "hidden_size =256\n",
    "net = AE()\n",
    "net = net.to(device)\n",
    "\n",
    "#Mean square loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#Parameters\n",
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-5\n",
    "\n",
    "#Optimizer and Scheduler\n",
    "#SGD\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "##RMSProp\n",
    "# torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "##Adam\n",
    "# torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "##Adagrad\n",
    "# torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, threshold=0.001, patience=5, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.7906\n",
      "Epoch [2/50], Loss: 0.7373\n",
      "Epoch [3/50], Loss: 0.7094\n",
      "Epoch [4/50], Loss: 0.6924\n",
      "Epoch [5/50], Loss: 0.6799\n",
      "Epoch [6/50], Loss: 0.6701\n",
      "Epoch [7/50], Loss: 0.6623\n",
      "Epoch [8/50], Loss: 0.6561\n",
      "Epoch [9/50], Loss: 0.6509\n",
      "Epoch [10/50], Loss: 0.6466\n",
      "Epoch [11/50], Loss: 0.6429\n",
      "Epoch [12/50], Loss: 0.6397\n",
      "Epoch [13/50], Loss: 0.6369\n",
      "Epoch [14/50], Loss: 0.6344\n",
      "Epoch [15/50], Loss: 0.6322\n",
      "Epoch [16/50], Loss: 0.6302\n",
      "Epoch [17/50], Loss: 0.6283\n",
      "Epoch [18/50], Loss: 0.6267\n",
      "Epoch [19/50], Loss: 0.6251\n",
      "Epoch [20/50], Loss: 0.6237\n",
      "Epoch [21/50], Loss: 0.6224\n",
      "Epoch [22/50], Loss: 0.6212\n",
      "Epoch [23/50], Loss: 0.6200\n",
      "Epoch [24/50], Loss: 0.6189\n",
      "Epoch [25/50], Loss: 0.6179\n",
      "Epoch [26/50], Loss: 0.6169\n",
      "Epoch [27/50], Loss: 0.6160\n",
      "Epoch [28/50], Loss: 0.6151\n",
      "Epoch [29/50], Loss: 0.6143\n",
      "Epoch [30/50], Loss: 0.6135\n",
      "Epoch [31/50], Loss: 0.6127\n",
      "Epoch [32/50], Loss: 0.6119\n",
      "Epoch [33/50], Loss: 0.6112\n",
      "Epoch [34/50], Loss: 0.6105\n",
      "Epoch [35/50], Loss: 0.6099\n",
      "Epoch [36/50], Loss: 0.6092\n",
      "Epoch [37/50], Loss: 0.6086\n",
      "Epoch [38/50], Loss: 0.6080\n",
      "Epoch [39/50], Loss: 0.6074\n",
      "Epoch [40/50], Loss: 0.6068\n",
      "Epoch [41/50], Loss: 0.6062\n",
      "Epoch [42/50], Loss: 0.6057\n",
      "Epoch [43/50], Loss: 0.6051\n",
      "Epoch [44/50], Loss: 0.6046\n",
      "Epoch [45/50], Loss: 0.6041\n",
      "Epoch [46/50], Loss: 0.6035\n",
      "Epoch [47/50], Loss: 0.6031\n",
      "Epoch [48/50], Loss: 0.6026\n",
      "Epoch [49/50], Loss: 0.6021\n",
      "Epoch [50/50], Loss: 0.6016\n",
      "Epoch [1/50], Loss: 0.5782\n",
      "Epoch [2/50], Loss: 0.5780\n",
      "Epoch [3/50], Loss: 0.5778\n",
      "Epoch [4/50], Loss: 0.5776\n",
      "Epoch [5/50], Loss: 0.5775\n",
      "Epoch [6/50], Loss: 0.5773\n",
      "Epoch [7/50], Loss: 0.5771\n",
      "Epoch [8/50], Loss: 0.5769\n",
      "Epoch [9/50], Loss: 0.5767\n",
      "Epoch [10/50], Loss: 0.5766\n",
      "Epoch [11/50], Loss: 0.5764\n",
      "Epoch [12/50], Loss: 0.5762\n",
      "Epoch [13/50], Loss: 0.5761\n",
      "Epoch [14/50], Loss: 0.5759\n",
      "Epoch [15/50], Loss: 0.5758\n",
      "Epoch [16/50], Loss: 0.5756\n",
      "Epoch [17/50], Loss: 0.5755\n",
      "Epoch [18/50], Loss: 0.5753\n",
      "Epoch [19/50], Loss: 0.5752\n",
      "Epoch [20/50], Loss: 0.5750\n",
      "Epoch [21/50], Loss: 0.5749\n",
      "Epoch [22/50], Loss: 0.5747\n",
      "Epoch [23/50], Loss: 0.5746\n",
      "Epoch [24/50], Loss: 0.5744\n",
      "Epoch [25/50], Loss: 0.5743\n",
      "Epoch [26/50], Loss: 0.5742\n",
      "Epoch [27/50], Loss: 0.5740\n",
      "Epoch [28/50], Loss: 0.5739\n",
      "Epoch [29/50], Loss: 0.5737\n",
      "Epoch [30/50], Loss: 0.5736\n",
      "Epoch [31/50], Loss: 0.5735\n",
      "Epoch [32/50], Loss: 0.5734\n",
      "Epoch [33/50], Loss: 0.5732\n",
      "Epoch [34/50], Loss: 0.5731\n",
      "Epoch [35/50], Loss: 0.5730\n",
      "Epoch [36/50], Loss: 0.5728\n",
      "Epoch [37/50], Loss: 0.5727\n",
      "Epoch [38/50], Loss: 0.5726\n",
      "Epoch [39/50], Loss: 0.5725\n",
      "Epoch [40/50], Loss: 0.5723\n",
      "Epoch [41/50], Loss: 0.5722\n",
      "Epoch [42/50], Loss: 0.5721\n",
      "Epoch [43/50], Loss: 0.5720\n",
      "Epoch [44/50], Loss: 0.5718\n",
      "Epoch [45/50], Loss: 0.5717\n",
      "Epoch [46/50], Loss: 0.5716\n",
      "Epoch [47/50], Loss: 0.5715\n",
      "Epoch [48/50], Loss: 0.5714\n",
      "Epoch [49/50], Loss: 0.5712\n",
      "Epoch [50/50], Loss: 0.5711\n",
      "Epoch [1/50], Loss: 0.5652\n",
      "Epoch [2/50], Loss: 0.5651\n",
      "Epoch [3/50], Loss: 0.5650\n",
      "Epoch [4/50], Loss: 0.5649\n",
      "Epoch [5/50], Loss: 0.5648\n",
      "Epoch [6/50], Loss: 0.5647\n",
      "Epoch [7/50], Loss: 0.5646\n",
      "Epoch [8/50], Loss: 0.5645\n",
      "Epoch [9/50], Loss: 0.5644\n",
      "Epoch [10/50], Loss: 0.5643\n",
      "Epoch [11/50], Loss: 0.5642\n",
      "Epoch [12/50], Loss: 0.5641\n",
      "Epoch [13/50], Loss: 0.5640\n",
      "Epoch [14/50], Loss: 0.5639\n",
      "Epoch [15/50], Loss: 0.5638\n",
      "Epoch [16/50], Loss: 0.5637\n",
      "Epoch [17/50], Loss: 0.5636\n",
      "Epoch [18/50], Loss: 0.5635\n",
      "Epoch [19/50], Loss: 0.5634\n",
      "Epoch [20/50], Loss: 0.5633\n",
      "Epoch [21/50], Loss: 0.5632\n",
      "Epoch [22/50], Loss: 0.5631\n",
      "Epoch [23/50], Loss: 0.5631\n",
      "Epoch [24/50], Loss: 0.5630\n",
      "Epoch   124: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch [25/50], Loss: 0.5629\n",
      "Epoch [26/50], Loss: 0.5628\n",
      "Epoch [27/50], Loss: 0.5627\n",
      "Epoch [28/50], Loss: 0.5626\n",
      "Epoch [29/50], Loss: 0.5625\n",
      "Epoch [30/50], Loss: 0.5624\n",
      "Epoch [31/50], Loss: 0.5623\n",
      "Epoch   131: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch [32/50], Loss: 0.5622\n",
      "Epoch [33/50], Loss: 0.5621\n",
      "Epoch [34/50], Loss: 0.5621\n",
      "Epoch [35/50], Loss: 0.5620\n",
      "Epoch [36/50], Loss: 0.5619\n",
      "Epoch [37/50], Loss: 0.5618\n",
      "Epoch [38/50], Loss: 0.5618\n",
      "Epoch   138: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch [39/50], Loss: 0.5617\n",
      "Epoch [40/50], Loss: 0.5616\n",
      "Epoch [41/50], Loss: 0.5616\n",
      "Epoch [42/50], Loss: 0.5615\n",
      "Epoch [43/50], Loss: 0.5614\n",
      "Epoch [44/50], Loss: 0.5614\n",
      "Epoch [45/50], Loss: 0.5613\n",
      "Epoch [46/50], Loss: 0.5613\n",
      "Epoch   146: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch [47/50], Loss: 0.5612\n",
      "Epoch [48/50], Loss: 0.5612\n",
      "Epoch [49/50], Loss: 0.5611\n",
      "Epoch [50/50], Loss: 0.5611\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Training\n",
    "TotalLoss = {}\n",
    "for index , hs in enumerate(hidden_sizes):\n",
    "    total_loss, cntr = 0, 0\n",
    "    epochLoss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i,(images,_) in enumerate(loader):\n",
    "\n",
    "            images = images.view(-1, 28*28)\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Initialize gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass (this calls the \"forward\" function within Net)\n",
    "            hidden_size = hs\n",
    "            outputs, _ = net(images)\n",
    "\n",
    "            # Find the loss\n",
    "            loss = criterion(outputs, images)\n",
    "\n",
    "            # Find the gradients of all weights using the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights using the optimizer and scheduler\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            cntr += 1\n",
    "\n",
    "        scheduler.step(total_loss/cntr)\n",
    "        print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, total_loss/cntr))\n",
    "        epochLoss.append(total_loss/cntr)\n",
    "    TotalLoss[hs] = epochLoss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(TotalLoss)\n",
    "#a= loss_plot(epochLoss)\n",
    "num_epochs = list(range(1,51))\n",
    "for _hs in hidden_sizes:\n",
    "#     print(num_epochs, _hs, hidden_sizes)\n",
    "    plt.plot(num_epochs, TotalLoss[_hs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMAI (py3.7env)",
   "language": "python",
   "name": "smai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
