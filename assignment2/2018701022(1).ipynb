{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "The objective of this assignment is to get you familiarizewith  the  problems  of  `classification`  and  `verification`with a popular problem space of `face`\n",
    "\n",
    "This jupyter notebook is meant to be used in conjunction with the full questions in the assignment pdf.\n",
    "\n",
    "## Instructions\n",
    "- Write your code and analyses in the indicated cells.\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Do not attempt to change the contents of the other cells.\n",
    "\n",
    "## Allowed Libraries\n",
    "- All libraries are allowed \n",
    "\n",
    "## Datasets \n",
    "- 3 datasets are provided. Load the data from the drive [link](!https://drive.google.com/file/d/1ujsKv9W5eidb4TXt1pnsqwDKVDFtzZTh/view?usp=sharing).\n",
    "- Unzip the downloaded file and store the files in a folder called `datasets`. Keep the `datasets` folder in the same directory as of the jupyter notebook \n",
    "\n",
    "## Submission\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Rename the notebook to `<roll_number>.ipynb` and submit ONLY the notebook file on moodle.\n",
    "- Upload  the  notebook,  report  and  classification  results as a zip file to moodle. Name the zip file as `<rollnumber>_assignment2.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (0.21.3)\n",
      "Requirement already satisfied: matplotlib in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (3.1.1)\n",
      "Requirement already satisfied: Pillow in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (6.2.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (from scikit-learn) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (from scikit-learn) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/sunil/my_projects/my_project_env/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing Libraries\n",
    "!pip install scikit-learn matplotlib Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "\n",
    "# Loading and plotting data\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Features\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.discriminant_analysis import _class_means,_class_cov\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "- Image size: Bigger images create better representation but would require more computation. Choose the correct image size based on your Laptop configuration. \n",
    "- is_grayscale: Should you take grayscale images? Or rgb images? Choose whichever gives better representation for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    'image_size': 32,\n",
    "    'is_grayscale': True,\n",
    "    'val_split': 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "cfw_dict = {'Amitabhbachan': 0,\n",
    "    'AamirKhan': 1,\n",
    "    'DwayneJohnson': 2,\n",
    "    'AishwaryaRai': 3,\n",
    "    'BarackObama': 4,\n",
    "    'NarendraModi': 5,\n",
    "    'ManmohanSingh': 6,\n",
    "    'VladimirPutin': 7}\n",
    "\n",
    "imfdb_dict = {'MadhuriDixit': 0,\n",
    "     'Kajol': 1,\n",
    "     'SharukhKhan': 2,\n",
    "     'ShilpaShetty': 3,\n",
    "     'AmitabhBachan': 4,\n",
    "     'KatrinaKaif': 5,\n",
    "     'AkshayKumar': 6,\n",
    "     'Amir': 7}\n",
    "\n",
    "# Load Image using PIL for dataset\n",
    "def load_image(path):\n",
    "    im = Image.open(path).convert('L' if opt['is_grayscale'] else 'RGB')\n",
    "    im = im.resize((opt['image_size'],opt['image_size']))\n",
    "    im = np.array(im)\n",
    "    im = im/256\n",
    "    return im\n",
    "\n",
    "# Load the full data from directory\n",
    "def load_data(dir_path):\n",
    "    image_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    if \"CFW\" in dir_path:\n",
    "        label_dict = cfw_dict\n",
    "\n",
    "    elif \"yale\" in dir_path.lower():\n",
    "        label_dict = {}\n",
    "        for i in range(15):\n",
    "            label_dict[str(i+1)] = i\n",
    "    elif \"IMFDB\" in dir_path:\n",
    "        label_dict = imfdb_dict\n",
    "    else:\n",
    "        raise KeyError(\"Dataset not found.\")\n",
    "    \n",
    "    \n",
    "    for filename in sorted(os.listdir(dir_path)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            im = load_image(os.path.join(dir_path,filename))\n",
    "            y = filename.split('_')[0]\n",
    "            y = label_dict[y] \n",
    "            image_list.append(im)\n",
    "            y_list.append(y)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    image_list = np.array(image_list)\n",
    "    y_list = np.array(y_list)\n",
    "\n",
    "    print(\"Dataset shape:\",image_list.shape)\n",
    "\n",
    "    return image_list,y_list\n",
    "\n",
    "# Display N Images in a nice format\n",
    "def disply_images(imgs,classes,row=1,col=2,w=64,h=64):\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    for i in range(1, col*row +1):\n",
    "        img = imgs[i-1]\n",
    "        fig.add_subplot(row, col, i)\n",
    "        \n",
    "        if opt['is_grayscale']:\n",
    "            plt.imshow(img , cmap='gray') \n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        \n",
    "        plt.title(\"Class:{}\".format(classes[i-1]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n",
      "(165, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# eg.\n",
    "dirpath = 'dataset/Yale_face_database'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show sample images\n",
    "ind = np.random.randint(0,y.shape[0],6)\n",
    "disply_images(X[ind,...],y[ind], row=2,col=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "    You are provided 6 Features. These features are:\n",
    "   - Eigen Faces / PCA \n",
    "   - Kernel PCA\n",
    "   - Fisher Face / LDA\n",
    "   - Kernel Fisher Face\n",
    "   - VGG Features \n",
    "   - Resnet Features\n",
    "\n",
    "**VGG and Resnet features are last layer features learned by training a model for image classification**\n",
    "    \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Flatten to apply PCA/LDA\n",
    "X = X.reshape((N,H*W*C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Eigen Face:\n",
    "Use principal component analysis to get the eigen faces. \n",
    "Go through the [documentation](!http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) on how to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(X,k):\n",
    "    \"\"\"\n",
    "        Get PCA of K dimension using the top eigen vectors \n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=k)\n",
    "    X_k = pca.fit_transform(X)\n",
    "    return X_k, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Kernel Face:\n",
    "Use Kernel principal component analysis to get the eigen faces. \n",
    "\n",
    "There are different kernels that can be used. Eg. Poly, rbf, sigmoid. Choose the whichever gives the best result or representation. See [link](!https://data-flair.training/blogs/svm-kernel-functions/) for better understanding of these kernels  \n",
    "\n",
    "Go through the [documentation](!https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA) on how to use it different kernels in Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_pca(X, k,kernel='rbf', degree=3):\n",
    "    \"\"\"\n",
    "        Get PCA of K dimension using the top eigen vectors \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "        @param: kernel => which kernel to use (“linear” | “poly” | “rbf” | “sigmoid” | “cosine” )\n",
    "        @param: d => Degree for poly kernels. Ignored by other kernels\n",
    "    \"\"\"\n",
    "    kpca = KernelPCA(n_components=k,kernel=kernel,degree=degree)\n",
    "    X_k = kpca.fit_transform(X)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fisher Face\n",
    "Another method similar to the eigenface technique is `fisherfaces` which uses linear discriminant analysis.\n",
    "This method for facial recognition is less sensitive to variation in lighting and pose of the face than using eigenfaces. Fisherface uses labelled data to retain more of the class-specific information during the dimension reduction stage.\n",
    "\n",
    "Go through the [documentation](!https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) on how to use it different kernels in Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda(X,y, k):\n",
    "    \"\"\"\n",
    "        Get LDA of K dimension \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "    \"\"\"\n",
    "    lda = LDA(n_components=k)\n",
    "    X_k = lda.fit_transform(X,y)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Kernel Fisher Face\n",
    "Use LDA using different kernels similiar to KernelPCA. Here the input is directly transformed instead of using the kernel trick.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_lda(X,y,k,kernel='rbf',degree=3):\n",
    "    \"\"\"\n",
    "        Get LDA of K dimension \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "        @param: kernel => which kernel to use ( “poly” | “rbf” | “sigmoid”)\n",
    "    \"\"\"\n",
    "    # Transform  input\n",
    "    if kernel == \"poly\":\n",
    "        X_transformed = X**degree\n",
    "    elif kernel == \"rbf\":\n",
    "        var = np.var(X)\n",
    "        X_transformed= np.exp(-X/(2*var))\n",
    "    elif kernel == \"sigmoid\":\n",
    "        X_transformed = np.tanh(X)\n",
    "    else: \n",
    "        raise NotImplementedError(\"Kernel {} Not defined\".format(kernel))\n",
    "        \n",
    "    klda = LDA(n_components=k)\n",
    "    X_k = klda.fit_transform(X_transformed,y)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. VGG Features\n",
    "VGG Neural Networks a 19 layer CNN architecture introduced by Andrew Zisserman([Link](!https://arxiv.org/pdf/1409.1556.pdf) to paper). We are providing you with the last fully connected layer of this model.\n",
    "\n",
    "The model was trained for face classification on each dataset and each feature the dimension of 4096."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_features(dirpath):\n",
    "    features = np.load(os.path.join(dirpath,\"VGG19_features.npy\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Resnet Features\n",
    "\n",
    "[Residual neural networks](!https://arxiv.org/pdf/1512.03385.pdf) are CNN with large depth, to effectively train these netwrorks they utilize skip connections, or short-cuts to jump over some layers. This helps solving [vanishing gradient problem](!https://en.wikipedia.org/wiki/Vanishing_gradient_problem) \n",
    "\n",
    "A 50 layer resnet model was trained for face classification on each dataset. Each feature the dimension of 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_features(dirpath):\n",
    "    features = np.load(os.path.join(dirpath,\"resnet50_features.npy\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1(a). What are eigen faces? \n",
    "\n",
    "___________________________\n",
    "\n",
    "* Eigenfaces can be considered a set of \"standardized face ingredients\", derived from statistical analysis of many pictures of faces.\n",
    "* A set of eigenfaces can be generated by performing a mathematical process called dimensionality reduction techniques like principal component analysis (PCA)/ Linear Discriminant Analysis on a large set of images depicting different human faces. \n",
    "* Any human face can be considered to be a combination of these standard faces.\n",
    "* Eigenfaces is the name given to a set of \"eigenvectors\", which are derived from the covariance matrix of the probability distribution over the high-dimensional vector space of face images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(b).  How many eigen vec-tors/faces are required to “satisfactorily” reconstruct a  person  in  these  three  datasets? (Don’t  forget  to make your argument based on eigen value spectrum) Show appropriate graphs, qualitative examples andmake a convincing argument.\n",
    "\n",
    "* We'll considered the eigen vectors/faces corresponding largest eigen values to reduce the dimensionality of face images. \n",
    "* By considering the eigen value spectrum, there is variation in first 25 eigen vectors. After these 25 eigen vectors there is not much variation in remaining eigen vectors.\n",
    "* If we draw the bar graph for first 25 eigen values, after 10 eigen vectors the plot is constantly decreasing.\n",
    "\n",
    "-------------------------------------------------\n",
    "\n",
    "* To reconstruct a person face atleast we need 25 eigen vectors. For satisfactory faces atleast 64 eigen vectors are required. And I observed is that if we increase the number of eigen vectors then quality of reconstructing face images increasing. \n",
    "* According to my observation 64 to 128(in between) eigen vectors/faces are required to “satisfactorily” reconstruct a  person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-dbb0d599b6cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute your features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca_X_3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkpca_X_3D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_kernel_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlda_X_3D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mklda_X_3D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_kernel_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-224a8ca3090e>\u001b[0m in \u001b[0;36mget_pca\u001b[0;34m(X, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_projects/my_project_env/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \"\"\"\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_projects/my_project_env/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 382\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_projects/my_project_env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 539\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# Compute your features \n",
    "pca_X_3D, _ = get_pca(X,64)\n",
    "kpca_X_3D = get_kernel_pca(X,64)\n",
    "lda_X_3D = get_lda(X,y,3)\n",
    "klda_X_3D = get_kernel_lda(X,y,3)\n",
    "vgg = get_vgg_features(dirpath)\n",
    "res = get_resnet_features(dirpath)\n",
    "print(vgg.shape, res.shape, y.shape)\n",
    "print(dirpath)\n",
    "#vgg_lda_X_3D = get_kernel_lda(get_vgg_features(dirpath),y,3)\n",
    "res_lda_X_3D = get_kernel_lda(get_resnet_features(dirpath),y,3)\n",
    "vgg_pca_X_3D, _ = get_pca(get_vgg_features(dirpath), 64)\n",
    "res_pca_X_3D = get_kernel_pca(get_resnet_features(dirpath), 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot  \n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(421, projection='3d')\n",
    "scatter = ax.scatter(pca_X_3D[:,0],pca_X_3D[:,1], pca_X_3D[:,2],c=y)\n",
    "plt.title(\"PCA\")\n",
    "ax.add_artist(ax.legend(*scatter.legend_elements(), loc=\"lower left\", title=\"Classes\"))\n",
    "ax = fig.add_subplot(422, projection='3d')\n",
    "ax.scatter(kpca_X_3D[:,0],kpca_X_3D[:,1],kpca_X_3D[:,2],c=y)\n",
    "plt.title(\"KPCA\")\n",
    "ax = fig.add_subplot(423, projection='3d')\n",
    "ax.scatter(lda_X_3D[:,0],lda_X_3D[:,1],lda_X_3D[:,2],c=y)\n",
    "plt.title(\"LDA\")\n",
    "ax = fig.add_subplot(424, projection='3d')\n",
    "ax.scatter(klda_X_3D[:,0],klda_X_3D[:,1],klda_X_3D[:,2],c=y)\n",
    "plt.title(\"KLDA\")\n",
    "ax = fig.add_subplot(425, projection='3d')\n",
    "ax.scatter(vgg_lda_X_3D[:,0],vgg_lda_X_3D[:,1],vgg_lda_X_3D[:,2],c=y)\n",
    "plt.title(\"VGG+LDA\")\n",
    "ax = fig.add_subplot(426, projection='3d')\n",
    "scatter = ax.scatter(res_lda_X_3D[:,0],res_lda_X_3D[:,1],res_lda_X_3D[:,2],c=y)\n",
    "plt.title(\"ResNet+LDA\")\n",
    "ax = fig.add_subplot(427, projection='3d')\n",
    "ax.scatter(vgg_pca_X_3D[:,0],vgg_pca_X_3D[:,1],vgg_pca_X_3D[:,2],c=y)\n",
    "plt.title(\"VGG+PCA\")\n",
    "ax = fig.add_subplot(428, projection='3d')\n",
    "ax.scatter(res_pca_X_3D[:,0],res_pca_X_3D[:,1],res_pca_X_3D[:,2],c=y)\n",
    "plt.title(\"ResNet+PCA\")\n",
    "ax.add_artist(ax.legend(*scatter.legend_elements(), loc=\"lower left\", title=\"Classes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the eigen value spectrum \n",
    "cov_mat = np.cov(X)\n",
    "eigval, eigvec = np.linalg.eig(cov_mat.T)\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(121)\n",
    "plt.plot(list(range(0,25)), eigval[0:25])\n",
    "plt.title(\"Eigen value spectrum(plot)\")\n",
    "plt.ylabel(\"eigen values\")\n",
    "ax = fig.add_subplot(122)\n",
    "plt.bar(list(range(0,25)), eigval[0:25])\n",
    "plt.title(\"Eigen value spectrum(Bar graph)\")\n",
    "plt.ylabel(\"eigen values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(c). Reconstruct  the  image  back for each case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_images(X, n_comp):\n",
    "    \"\"\"\n",
    "        Reconstruct the images back by just using the selected principal components. \n",
    "\n",
    "\n",
    "        You have to write the code in this code block.\n",
    "        You can change the functions provided above (eg, get_pca, get_lda) for your use case. \n",
    "            \n",
    "        @params: \n",
    "                Input parameters\n",
    "\n",
    "        @return reconstructed_X => reconstructed image\n",
    "        \n",
    "    \"\"\"\n",
    "    X_proj,pca = get_pca(X, n_comp)\n",
    "    X_proj_inv = pca.inverse_transform(X_proj)\n",
    "    return X_proj_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results \n",
    "X_reconstructed = reconstruct_images(X, n_comp=256)\n",
    "X_proj_img = np.reshape(X_reconstructed,(400,32, 32))\n",
    "fig = plt.figure(figsize=(5,5)) \n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n",
    "\n",
    "for i in range(8): \n",
    "    ax = fig.add_subplot(4,4, i+1, xticks=[], yticks=[]) \n",
    "    ax.imshow(X_proj_img[i], cmap=plt.cm.bone, interpolation='nearest')\n",
    "\n",
    "#Reconstructed Image Error\n",
    "print(\"reconstructed error: \", np.sqrt(np.mean((X - X_reconstructed)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(d). Which person/identity is difficult to represent com-pactly with fewer eigen vectors?  Why is that?  Explain with your empirical observations and intuitive answers\n",
    "\n",
    "----------------------------------------------------------------\n",
    "* Amitab Bacchan face is difficult to represent compactly with fewer eigen vectors \"32\". \n",
    "* For empirical observation, Class-wise reconstruction error calculated for these 32 eigen vectors. In that class-4 (Amitab Bacchan) have the high reconstruction error rate. \n",
    "* In IMFDB dataset, class-4 person face contains more facial epressions. Every image contains different facial expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here\n",
    "classes = list(imfdb_dict.values())\n",
    "print\n",
    "error = 0\n",
    "for i in classes:\n",
    "    each_class_data = X[np.nonzero(y == i)]\n",
    "    X_reconstructed = reconstruct_images(each_class_data, n_comp=32)\n",
    "    error_temp = np.sqrt(np.mean((each_class_data - X_reconstructed)**2))\n",
    "    if(error_temp>error):\n",
    "        error = error_temp\n",
    "        error_class = i\n",
    "print(error, error_class)\n",
    "for name, b in imfdb_dict.items():\n",
    "    if b == error_class:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2(a). Use any classifier(MLP, Logistic regression, SVM, Decision Trees) and find the classification accuracy. \n",
    "\n",
    "2(b)Which method works well? Do a comparitivestudy. \n",
    "\n",
    "* I used MLP classifier with hidden layes size=(150, 200, 150), tanh activation fucntion and optimizer is adam. Train and validate this model on all different methods (PCA, Kernel PCA, LDA, Kernel LDA, VggNet+PCA, VggNet+LDA, ResNet+PCA, ResNet+LDA). \n",
    "* VggNet+LDA method works well. It gave the 100% accuracy on test dataset contain 50 images. If we observe the 3d spectrum of above mentioned all methods then in that VggNet+LDA and ResNet+LDA methods spectrum quite different and all classes are spreaded without any overlaps. \n",
    "* Why VGG and ResNet working very well? Because these two are already trained on large amount of data and VGG network contains 16/19 layes. By removing last layer using these networks for our datasets. \n",
    "* According to my observation VGGNet+LDA and ResNet+LDA methods are best!\n",
    "\n",
    "You already know the paper [Face Recognition Us-ing  Kernel  Methods](!http://face-rec.org/algorithms/Kernel/nips01.pdf) .See  this  as  an  example for empirical analysis of different features/classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your classifier here. You can use libraries like sklearn to create your classifier \n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self, ):\n",
    "        super(Classifier, self).__init__()\n",
    "    \n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    \n",
    "    def classify(self,X):\n",
    "        \"\"\"\n",
    "            Given an input X classify it into appropriate class. \n",
    "        \"\"\"\n",
    "        prediction = self.mlp.predict(X)     \n",
    "        return prediction\n",
    "        \n",
    "    def confusion_matrix(self,pred,y):\n",
    "        \"\"\"\n",
    "            A confusion matrix is a table that is often used to describe the performance of a classification\n",
    "            model (or “classifier”) on a set of test data for which the true values are known.\n",
    "            \n",
    "            \n",
    "            @return confusion_matrix => num_classesxnum_classes martix \n",
    "                where confusion_matrix[i,j] = number of prediction which are i and number of ground truth value equal j \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "    def train(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "    \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        self.mlp = MLPClassifier(hidden_layer_sizes=(150,200,150), max_iter=500, activation = 'tanh',solver='adam',random_state=1)\n",
    "        self.mlp.fit(X_train, y_train)\n",
    "        \n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is the classifier on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters and judge the classification\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier validated. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "        y_pred = self.mlp.predict(X_validate)\n",
    "        confusion_mat = confusion_matrix(y_validate, y_pred)\n",
    "        acc = accuracy_score(y_validate, y_pred)\n",
    "        #print(\"Validation Accuracy: \", acc)\n",
    "        scores = precision_recall_fscore_support(y_validate, y_pred, average='macro')\n",
    "        #print(\"Precision, Recall, f1-score: \",scores[0], scores[1], scores[2])\n",
    "        return scores[0], scores[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_model(method, method_names):\n",
    "    all_acc1 = []\n",
    "    all_precision1 = []\n",
    "    all_f1score1 = []\n",
    "    accuracy = 0\n",
    "    for i in range(len(method)):\n",
    "        #print(\"Results of \"+method_names[i]+\" method:\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(method[i], y, test_size=0.6, random_state=42)\n",
    "        X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "        classifier = Classifier()\n",
    "        classifier.train(X_train, y_train)\n",
    "        precision, f1_score = classifier.validate(X_valid, y_valid)\n",
    "        y_pred = classifier.classify(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        all_acc1.append(acc)\n",
    "        all_precision1.append(precision)\n",
    "        all_f1score1.append(f1_score)\n",
    "        #print(\"Test Data accuracy: \", acc)\n",
    "        if(accuracy<acc):\n",
    "            confusion_mat1 = confusion_matrix(y_test, y_pred)\n",
    "            best_method1 = method_names[i]\n",
    "            accuracy = acc\n",
    "    return confusion_mat1, best_method1, all_acc1, all_precision1, all_f1score1     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 tables simiar to page-6 of the paper. One table per dataset \n",
    "# Each table will have 5 columns. \n",
    "# Feature/combination of feature used, reduced dimension space, classification error, accuracy, f1-score\n",
    "\n",
    "# Print the table. (You can use Pandas)\n",
    "method =[pca_X_3D, kpca_X_3D, lda_X_3D, klda_X_3D, vgg_lda_X_3D, res_lda_X_3D, vgg_pca_X_3D, res_pca_X_3D]\n",
    "method_names = ['PCA', 'Kernel PCA', 'LDA', 'Kernel LDA', 'VGGnet+LDA', 'Resnet+LDA', 'VGGnet+PCA','Resnet+LDA']\n",
    "best_model_confusion_mat1, best_method1, all_acc1, all_precision1, all_f1score1 = train_model(method, method_names)\n",
    "df = pd.DataFrame()\n",
    "df.insert(0, \"Feature\", method_names)\n",
    "df.insert(1, \"Dimension Space\", [64, 64, 3,3,3,3,64,64])\n",
    "df.insert(2, \"Accuracy\", all_acc1)\n",
    "df.insert(3, \"Precision\", all_precision1)\n",
    "df.insert(4, \"f1-score\", all_f1score1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset print the confusion matrix for the best model \n",
    "print(\"Confusion matrix for \", best_method1)\n",
    "print(best_model_confusion_mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Similiar to 1(b) use t-SNE based visilization of faces?  Does it makesense?  Do you see similar people coming together?or something else?  Can you do visualization datasetwise and combined? Here you will use a popular implementation.(Worth  reading and understanding  t-SNE.  We  will not discuss it in the class and out of scope for thiscourse/exams.\n",
    "\n",
    "    * t-SNE creates a reduced feature space where similar samples are modeled by nearby points and dissimilar samples are modeled by distant points with high probability.\n",
    "    * For IMFDB dataset this technique doesn't make any sense. If we observe the below visualization output all people/classes are coming together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TSNE for different features and create a scatter plot\n",
    "\n",
    "k = 3 # Number of components in TSNE\n",
    "\n",
    "# Compute\n",
    "X_TSNE = TSNE(n_components=k).fit_transform(X)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(X_TSNE[:,0],X_TSNE[:,1], X_TSNE[:,2],c=y)\n",
    "plt.title(\"t-SNE\")\n",
    "ax.add_artist(ax.legend(*scatter.legend_elements(), loc=\"upper left\", title=\"Classes\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.`face`  is  used  for  verification.   \n",
    "\n",
    "4(a) How do we formulate the problem using KNN \n",
    "\n",
    "* Divided the total dataset into 60% for train, 20% for validation, 20% for test.\n",
    "* Determine parameter K = number of nearest neighbors. I tested with 3 different K = {3, 5, 7} values, found the K=5 is the best.\n",
    "* Calculate the distance between the query-instance in test dataset and all the training samples.\n",
    "* Calculate the distance between the query-instance in validation dataset and all the training samples.\n",
    "* Gather the category Y of the nearest neighbors for test and validation dataset.\n",
    "* Use simple majority of the category of nearest neighbors as the prediction value of the query instance.\n",
    "\n",
    "4(b) How do we analyze the performance ? suggest  the  metrics  (like  accuracy) that is appropriate for this task.\n",
    " \n",
    " * Performance of KNN totally depends on the distance metric and K value.\n",
    " * For our model used the Mintowski distance measure and K=5.\n",
    " * To calculate the distance we can use the other distnce metrics like L1-Norm, L2-Norm, weighted distance function, cosine similarity. \n",
    "_______________________________________________________________________\n",
    "\n",
    "4(c)Show empirical re-sults  with  all  the  representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceVerification():\n",
    "    def __init__(self, ):\n",
    "        super(FaceVerification, self).__init__()\n",
    "    \n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    \n",
    "    def verify(self,X):\n",
    "        \"\"\"\n",
    "            Given an input X find if the class id is correct or not.\n",
    "            \n",
    "            @return verfication_results => N vector containing True or False. \n",
    "                    If the class-id matches with your prediction then true else false.   \n",
    "        \"\"\"\n",
    "        verfication_results = self.knn.predict(X)             \n",
    "        return verfication_results\n",
    "        \n",
    "    def train(self,X_train,y_train, k):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your verification system will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "    \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        self.knn.fit(X_train, y_train)\n",
    "        \n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is your system on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "        y_pred = self.knn.predict(X_validate)\n",
    "        confusion_mat = confusion_matrix(y_validate, y_pred)\n",
    "        acc = accuracy_score(y_validate, y_pred)\n",
    "        #print(\"Validation Accuracy: \", acc)\n",
    "        scores = precision_recall_fscore_support(y_validate, y_pred, average='macro')\n",
    "        #print(\"Precision, Recall, f1-score: \",scores[0], scores[1], scores[2])\n",
    "        return scores[0], scores[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train and validation split and show your results \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_model(method, method_names):\n",
    "    all_acc = []\n",
    "    all_precision = []\n",
    "    all_f1score = []\n",
    "    accuracy = 0\n",
    "    for i in range(len(method)):\n",
    "        #print(\"Results of \"+method_names[i]+\" method:\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(method[i], y, test_size=0.6, random_state=42)\n",
    "        X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "        classifier = FaceVerification()\n",
    "        classifier.train(X_train, y_train, k=5)\n",
    "        precision, f1_score = classifier.validate(X_valid, y_valid)\n",
    "        y_pred = classifier.verify(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        all_acc.append(acc)\n",
    "        all_precision.append(precision)\n",
    "        all_f1score.append(f1_score)\n",
    "        #print(\"Test Data accuracy: \", acc)\n",
    "        if(accuracy<acc):\n",
    "            confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "            best_method = method_names[i]\n",
    "            accuracy = acc\n",
    "    return confusion_mat, best_method, all_acc, all_precision, all_f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 tables simiar to page-6 of the paper. One table per dataset \n",
    "# Each table will have 5 columns. \n",
    "# Feature/combination of feature used, reduced dimension space, verification error, accuracy, precision\n",
    "\n",
    "method =[pca_X_3D, kpca_X_3D, lda_X_3D, klda_X_3D, vgg_lda_X_3D, res_lda_X_3D, vgg_pca_X_3D, res_pca_X_3D]\n",
    "method_names = ['PCA', 'Kernel PCA', 'LDA', 'Kernel LDA', 'VGGnet+LDA', 'Resnet+LDA', 'VGGnet+PCA','Resnet+LDA']\n",
    "best_model_confusion_mat, best_method, all_acc, all_precision, all_f1score = train_model(method, method_names)\n",
    "df1 = pd.DataFrame()\n",
    "df1.insert(0, \"Feature\", method_names)\n",
    "df1.insert(1, \"Dimension Space\", [64, 64, 3,3,3,3,64,64])\n",
    "df1.insert(2, \"Accuracy\", all_acc)\n",
    "df1.insert(3, \"Precision\", all_precision)\n",
    "df1.insert(4, \"f1-score\", all_f1score)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extenstion / Application\n",
    "    Create a system for any one of the following problems:\n",
    "\n",
    "- Politicians  vs  Filmstars  in  a  public  data  set.   (eg.LFW)\n",
    "        You already have seen IIIT-CFW dataset. Use it for classification. \n",
    "- Age prediction\n",
    "        Given different actors/actress in IMFDB create new labels based on their age.  \n",
    "- Gender prediction\n",
    "        Given different actors/actress in IMFDB+IIIT-CFW create new labels based on their gender.\n",
    "- Emotion classification\n",
    "        Both the yale dataset and IMFDB contain an `emotion.txt` file. Using that you can create a emotion predicter \n",
    "- cartoon vs real images\n",
    "        Use a combination of IIIT-CFW and other dataset. \n",
    "        \n",
    "\n",
    "\n",
    "You are free to use a new dataset that is publicly avail-able or even create one by crawling from internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your classifier\n",
    "\n",
    "# Validate your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show qualitative results such as accuracy, k-fold validation, TSNE/PCA/Isomap plots, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show quantitative results such as examples of correct prediction and wrong prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
